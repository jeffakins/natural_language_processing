{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d54a57",
   "metadata": {},
   "source": [
    "# Prepare Notebook\n",
    "This notebook will be used to work through the NLP prepare exercises and then turned into a .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac381312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import acquire as aq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845f902a",
   "metadata": {},
   "source": [
    "#### In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29de1abb",
   "metadata": {},
   "source": [
    "### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37634b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(dirty_words):\n",
    "    '''This function takes in words (single word, article, paragraph, etc) and then \n",
    "    lowercases all letters, normalizes the letters, and removes special characters'''\n",
    "    all_lower_case_words = dirty_words.lower()\n",
    "    normalized_words = unicodedata.normalize('NFKD', all_lower_case_words).encode('ascii', 'ignore').decode('utf-8')\n",
    "    remove_special_characters = re.sub(r\"[^a-z0-9'\\s]\", '', normalized_words)\n",
    "    return remove_special_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa17f2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is  test'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean('This is @ test!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e3aae",
   "metadata": {},
   "source": [
    "### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be024ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ca9d1",
   "metadata": {},
   "source": [
    "### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e954d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad21ad",
   "metadata": {},
   "source": [
    "### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eab32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0bc3f7",
   "metadata": {},
   "source": [
    "### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "- This function should define two optional parameters, extra_words and exclude_words. \n",
    "- These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e14a2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    # Add in 'extra_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "\n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e1d69",
   "metadata": {},
   "source": [
    "### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "008a400c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you die in metaverse, you die in real life:...</td>\n",
       "      <td>2021-10-30T07:16:16.000Z</td>\n",
       "      <td>Kiran Khatri</td>\n",
       "      <td>After Facebook changed the company's name to M...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elon Musk becomes world's 1st person to cross ...</td>\n",
       "      <td>2021-10-30T09:21:54.000Z</td>\n",
       "      <td>Kiran Khatri</td>\n",
       "      <td>Tesla CEO Elon Musk has become the world's fir...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Squid Game' crypto surges 1,00,000% in days, ...</td>\n",
       "      <td>2021-10-30T06:13:05.000Z</td>\n",
       "      <td>Kiran Khatri</td>\n",
       "      <td>A cryptocurrency called 'Squid Game', inspired...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mumbai Police shares meme on Facebook name cha...</td>\n",
       "      <td>2021-10-30T15:57:03.000Z</td>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>After Facebook changed its company name to 'Me...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reliance Jio declines AGR dues moratorium, bec...</td>\n",
       "      <td>2021-10-30T07:20:30.000Z</td>\n",
       "      <td>Kiran Khatri</td>\n",
       "      <td>Reliance Jio has reportedly said it won't opt ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  If you die in metaverse, you die in real life:...   \n",
       "1  Elon Musk becomes world's 1st person to cross ...   \n",
       "2  'Squid Game' crypto surges 1,00,000% in days, ...   \n",
       "3  Mumbai Police shares meme on Facebook name cha...   \n",
       "4  Reliance Jio declines AGR dues moratorium, bec...   \n",
       "\n",
       "                  published          author  \\\n",
       "0  2021-10-30T07:16:16.000Z    Kiran Khatri   \n",
       "1  2021-10-30T09:21:54.000Z    Kiran Khatri   \n",
       "2  2021-10-30T06:13:05.000Z    Kiran Khatri   \n",
       "3  2021-10-30T15:57:03.000Z  Arshiya Chopra   \n",
       "4  2021-10-30T07:20:30.000Z    Kiran Khatri   \n",
       "\n",
       "                                             content  category  \n",
       "0  After Facebook changed the company's name to M...  business  \n",
       "1  Tesla CEO Elon Musk has become the world's fir...  business  \n",
       "2  A cryptocurrency called 'Squid Game', inspired...  business  \n",
       "3  After Facebook changed its company name to 'Me...  business  \n",
       "4  Reliance Jio has reportedly said it won't opt ...  business  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = aq.get_inshorts_articles()\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0910d",
   "metadata": {},
   "source": [
    "### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28764d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boris – Behind the Billboards</td>\n",
       "      <td>Oct 3, 2021</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Codeup the Best Bootcamp in San Antonio…or ...</td>\n",
       "      <td>Sep 16, 2021</td>\n",
       "      <td>Looking for the best data science bootcamp in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Codeup Launches First Podcast: Hire Tech</td>\n",
       "      <td>Aug 25, 2021</td>\n",
       "      <td>Any podcast enthusiasts out there? We are plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why Should I Become a System Administrator?</td>\n",
       "      <td>Aug 23, 2021</td>\n",
       "      <td>With so many tech careers in demand, why choos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Announcing our Candidacy for Accreditation!</td>\n",
       "      <td>Jun 30, 2021</td>\n",
       "      <td>Did you know that even though we’re an indepen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     published  \\\n",
       "0                      Boris – Behind the Billboards   Oct 3, 2021   \n",
       "1  Is Codeup the Best Bootcamp in San Antonio…or ...  Sep 16, 2021   \n",
       "2           Codeup Launches First Podcast: Hire Tech  Aug 25, 2021   \n",
       "3        Why Should I Become a System Administrator?  Aug 23, 2021   \n",
       "4        Announcing our Candidacy for Accreditation!  Jun 30, 2021   \n",
       "\n",
       "                                             content  \n",
       "0                                                     \n",
       "1  Looking for the best data science bootcamp in ...  \n",
       "2  Any podcast enthusiasts out there? We are plea...  \n",
       "3  With so many tech careers in demand, why choos...  \n",
       "4  Did you know that even though we’re an indepen...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = aq.get_blog_articles()\n",
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bade7a1",
   "metadata": {},
   "source": [
    "### 8. For each dataframe, produce the following columns:\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d861477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    df['stemmed'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(stem)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    df['lemmatized'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(lemmatize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    return df[['title', column,'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb920bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boris – Behind the Billboards</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Codeup the Best Bootcamp in San Antonio…or ...</td>\n",
       "      <td>Looking for the best data science bootcamp in ...</td>\n",
       "      <td>looking best data science bootcamp world best ...</td>\n",
       "      <td>look best data scienc bootcamp world best code...</td>\n",
       "      <td>looking best data science bootcamp world best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Codeup Launches First Podcast: Hire Tech</td>\n",
       "      <td>Any podcast enthusiasts out there? We are plea...</td>\n",
       "      <td>podcast enthusiasts pleased announce release c...</td>\n",
       "      <td>ani podcast enthusiast pleas announc releas co...</td>\n",
       "      <td>podcast enthusiast pleased announce release co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why Should I Become a System Administrator?</td>\n",
       "      <td>With so many tech careers in demand, why choos...</td>\n",
       "      <td>many tech careers demand choose system adminis...</td>\n",
       "      <td>mani tech career demand whi choos system admin...</td>\n",
       "      <td>many tech career demand choose system administ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Announcing our Candidacy for Accreditation!</td>\n",
       "      <td>Did you know that even though we’re an indepen...</td>\n",
       "      <td>know even though independent school multiple r...</td>\n",
       "      <td>know even though independ school multipl regul...</td>\n",
       "      <td>know even though independent school multiple r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                      Boris – Behind the Billboards   \n",
       "1  Is Codeup the Best Bootcamp in San Antonio…or ...   \n",
       "2           Codeup Launches First Podcast: Hire Tech   \n",
       "3        Why Should I Become a System Administrator?   \n",
       "4        Announcing our Candidacy for Accreditation!   \n",
       "\n",
       "                                             content  \\\n",
       "0                                                      \n",
       "1  Looking for the best data science bootcamp in ...   \n",
       "2  Any podcast enthusiasts out there? We are plea...   \n",
       "3  With so many tech careers in demand, why choos...   \n",
       "4  Did you know that even though we’re an indepen...   \n",
       "\n",
       "                                               clean  \\\n",
       "0                                                      \n",
       "1  looking best data science bootcamp world best ...   \n",
       "2  podcast enthusiasts pleased announce release c...   \n",
       "3  many tech careers demand choose system adminis...   \n",
       "4  know even though independent school multiple r...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0                                                      \n",
       "1  look best data scienc bootcamp world best code...   \n",
       "2  ani podcast enthusiast pleas announc releas co...   \n",
       "3  mani tech career demand whi choos system admin...   \n",
       "4  know even though independ school multipl regul...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0                                                     \n",
       "1  looking best data science bootcamp world best ...  \n",
       "2  podcast enthusiast pleased announce release co...  \n",
       "3  many tech career demand choose system administ...  \n",
       "4  know even though independent school multiple r...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_article_data(codeup_df, 'content').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efdf118b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you die in metaverse, you die in real life:...</td>\n",
       "      <td>After Facebook changed the company's name to M...</td>\n",
       "      <td>facebook changed company ' name meta tesla ceo...</td>\n",
       "      <td>facebook chang compani ' name meta tesla ceo e...</td>\n",
       "      <td>facebook changed company ' name meta tesla ceo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elon Musk becomes world's 1st person to cross ...</td>\n",
       "      <td>Tesla CEO Elon Musk has become the world's fir...</td>\n",
       "      <td>tesla ceo elon musk become world ' first perso...</td>\n",
       "      <td>tesla ceo elon musk ha becom world ' first per...</td>\n",
       "      <td>tesla ceo elon musk ha become world ' first pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Squid Game' crypto surges 1,00,000% in days, ...</td>\n",
       "      <td>A cryptocurrency called 'Squid Game', inspired...</td>\n",
       "      <td>cryptocurrency called ' squid game ' inspired ...</td>\n",
       "      <td>cryptocurr call ' squid game ' inspir south ko...</td>\n",
       "      <td>cryptocurrency called ' squid game ' inspired ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mumbai Police shares meme on Facebook name cha...</td>\n",
       "      <td>After Facebook changed its company name to 'Me...</td>\n",
       "      <td>facebook changed company name ' meta ' mumbai ...</td>\n",
       "      <td>facebook chang compani name ' meta ' mumbai po...</td>\n",
       "      <td>facebook changed company name ' meta ' mumbai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reliance Jio declines AGR dues moratorium, bec...</td>\n",
       "      <td>Reliance Jio has reportedly said it won't opt ...</td>\n",
       "      <td>reliance jio reportedly said ' opt government ...</td>\n",
       "      <td>relianc jio ha reportedli said ' opt govern ' ...</td>\n",
       "      <td>reliance jio ha reportedly said ' opt governme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  If you die in metaverse, you die in real life:...   \n",
       "1  Elon Musk becomes world's 1st person to cross ...   \n",
       "2  'Squid Game' crypto surges 1,00,000% in days, ...   \n",
       "3  Mumbai Police shares meme on Facebook name cha...   \n",
       "4  Reliance Jio declines AGR dues moratorium, bec...   \n",
       "\n",
       "                                             content  \\\n",
       "0  After Facebook changed the company's name to M...   \n",
       "1  Tesla CEO Elon Musk has become the world's fir...   \n",
       "2  A cryptocurrency called 'Squid Game', inspired...   \n",
       "3  After Facebook changed its company name to 'Me...   \n",
       "4  Reliance Jio has reportedly said it won't opt ...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  facebook changed company ' name meta tesla ceo...   \n",
       "1  tesla ceo elon musk become world ' first perso...   \n",
       "2  cryptocurrency called ' squid game ' inspired ...   \n",
       "3  facebook changed company name ' meta ' mumbai ...   \n",
       "4  reliance jio reportedly said ' opt government ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  facebook chang compani ' name meta tesla ceo e...   \n",
       "1  tesla ceo elon musk ha becom world ' first per...   \n",
       "2  cryptocurr call ' squid game ' inspir south ko...   \n",
       "3  facebook chang compani name ' meta ' mumbai po...   \n",
       "4  relianc jio ha reportedli said ' opt govern ' ...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  facebook changed company ' name meta tesla ceo...  \n",
       "1  tesla ceo elon musk ha become world ' first pe...  \n",
       "2  cryptocurrency called ' squid game ' inspired ...  \n",
       "3  facebook changed company name ' meta ' mumbai ...  \n",
       "4  reliance jio ha reportedly said ' opt governme...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_article_data(news_df, 'content').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8d8cd",
   "metadata": {},
   "source": [
    "### 9. Ask yourself:\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you \n",
    "- prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
